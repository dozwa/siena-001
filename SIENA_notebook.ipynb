{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dieses Notebook dient Identifikation und Extraktion von Nutzeranforderungen.\n",
    "Mittels OpenAIs ChatGPT4 sollen Anforderungen aus Interviews abgeleitet werden. Diese werden gegen eine von fachlich versierten Personen erstelle Anforderungsliste verglichen, um die Güte der Anforderungsextraktion zu bewerten.\n",
    "Die Anforderungen werden hinsichtlich ihrer Klassifikation in funktionale und nicht-funktionale Anforderungen, sowie den Inhalt der Anforderung verglichen. Dabei werden nur direkt aus dem Text ableitbare Anforderungen verglichen, implizite Anforderungen werden hier nicht betrachtet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "# OpenAI API key for SIENA project\n",
    "\n",
    "openai.api_key  = \"YOUR_API_KEY\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function to get the completion from the API\n",
    "\n",
    "def get_completion_from_messages(messages, model, temperature):\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=temperature, # this is the degree of randomness of the model's output\n",
    "    )\n",
    "#     print(str(response.choices[0].message))\n",
    "    return response.choices[0].message[\"content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_dataframe(text):\n",
    "    # Split des Textes in einzelne Anforderungen\n",
    "    requirements = text.split('\\n')\n",
    "\n",
    "    # Initialisierung der Spalten des Dataframes\n",
    "    columns = ['Klassifikation', 'Anforderung', 'Beschreibung', 'Zitat']\n",
    "\n",
    "    # Erstellen des Dataframes\n",
    "    data = pd.DataFrame(columns=columns)\n",
    "\n",
    "    # Iteration über jede Anforderung\n",
    "    for requirement in requirements:\n",
    "        # Split der Anforderung in Klassifikation, Anforderung, Beschreibung und Zitat\n",
    "        parts = requirement.split('; ')\n",
    "\n",
    "        # Überprüfen, ob die Anforderung alle erforderlichen Teile enthält\n",
    "        if len(parts) == 4:\n",
    "            # Hinzufügen der Anforderung zum Dataframe\n",
    "            row = pd.Series({\n",
    "                'Klassifikation': parts[0],\n",
    "                'Anforderung': parts[1],\n",
    "                'Beschreibung': parts[2],\n",
    "                'Zitat': parts[3][1:]\n",
    "            })\n",
    "            data = pd.concat([data, row], axis=1)\n",
    "        else:\n",
    "            # Ausgabe einer Fehlermeldung für die fehlerhafte Anforderung\n",
    "            #print(\"Ungültige Anforderung: \" + requirement)\n",
    "            global req_failures \n",
    "            req_failures += 1\n",
    "\n",
    "    # Dataframe zurückgeben\n",
    "    return data.T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I: Dankeschön Interviewer 2, ich finde das auch total spannend. Du scheinst schon ziemlich konkrete Vorstellungen zu haben, was du brauchen würdest. Klang jetzt zumindest so raus. Und genau, es ist auch unsere Frage, also, wie müssen Informationen optimal aufbereitet werden? Wie müssen sie optimal bereitgestellt werden, damit du sie auch tatsächlich praxistauglich, würde ich jetzt mal verklausulieren, auch konsumieren kannst, um dich entsprechend zu informieren und da auch ein Vertrauen in diese Informationen, die da bereitgestellt werden, entwickeln kannst? Und ohne das jetzt zu sehr irgendwie in eine Form pressen zu wollen, wir sagen nicht ohne Grund, digitales Tool, was entwickelt werden soll. Würde ich mir jetzt von dir gerne mal … #00:18:45#, was du dir vorstellst als Lösung, wie dir genau diese Probleme, die du gerade schon beschrieben hast und diese Qualität, die du beschrieben hast, dann auch liefern kann?\n",
      "B: Also, ich könnte mir zum Beispiel vorstellen, dass das eine App ist, die man sozusagen auf dem Handy hat. Weil ich meine, das Handy ist einfach allgegenwärtig, das hat jeder. Ich habe es in der Behandlung nie dabei, weil ich das nicht besonders-, weil ich das unhöflich finde. Aber man hat es im Spind, das heißt, man hat die Möglichkeit auch mal, wenn man-, ich meine, man muss auch irgendwann mal zur Toilette gehen, oder irgendwann mal ein Glas Wasser trinken, um irgendwie über den Tag bis zu seiner Mittagspause zu kommen. Dann könnte man auch in diesem Moment in diese App gehen, einmal den Suchbegriff reinhauen, und gucken, ok, spuckt der mir hier irgendwie zumindest mal 20 Sätze raus, wo man sagen kann, ok, ich habe eine kurze Übersicht, was ist das Ganze. Ich habe eine kurze Übersicht, die und diese und jene Therapiemöglichkeit gibt es jetzt mal unabhängig von physiotherapeutischer Seite. Und dann so, gibt es Studienlagen? Wenn ja, was sagen die aus? Wenn nein, ok, gibt es irgendwas, was sich aus Expertenmeinung, Erfahrungsmeinung herausklamüsert hat? Und wenn es Studien gibt, was ist die Quintessenz und was wird als Best Practice daraus sozusagen konkludiert und dann eben auch empfohlen? Das wäre was, was ich total geil finden würde. Weil für den ganzen anderen Kram, also so Sachen, wie dann mehr Background Informationen, sowas, dafür kann man dann Sachen, wie Physiomed Science, wie Physio Bib und, oder auch bei Papmed sich die Studie nochmal genauer durchlesen. Das hat man dann durchaus. Aber ich finde so ein bisschen so diese-, ich meine, ich will mir von einer App nicht vorschreiben lassen, was ich zu tun habe. Ich will aber trotzdem haben, ok, weil wenn wir mit dem Anspruch arbeiten wollen, wir wollen eine wissenschaftliche Physiotherapie. Und ich muss dann sagen, ich habe keinen Studienabschluss, ich habe sozusagen die Ausbildung gemacht, weil ich eigentlich mal Medizin studieren wollte. Gut, haben wir verworfen, ist was anderes. Aber grundsätzlich einfach habe ich den Anspruch da an mich, ok, ich will aber auf dieser Basis arbeiten, zu sagen, wenn wir schon die Physiotherapie weiterentwickeln wollen, dann brauchen wir einen evidenzbasierten Ansatz. Und ich finde, dass man dafür dann auch mal diese Handlungsanweisung braucht, wo da einfach drinsteht, so. Und da haben japanische Forscher rausgefunden, sie machen dieses und jenes Übungsprogramm für die nächsten vier Wochen mit dem Umfang. Dieses und jenes und dann hatten die den und den Outcome. Das fände ich total geil. Ob man das genauso dann umsetzen muss, das steht auf einem anderen Blatt Papier. Aber sozusagen zumindest so die Informationsdarbietung, was könnte man tun, und was ist sozusagen rein vom wissenschaftlichen Stand her das Beste, was man aktuell weiß.\n"
     ]
    }
   ],
   "source": [
    "# interviewauschnitte laden und als dataframe speichern\n",
    "\n",
    "df_01 = pd.read_excel(\"SIENA_data_interviews.xlsx\")\n",
    "\n",
    "for question in df_01[\"Interviewausschnitt\"]:\n",
    "    print(question)\n",
    "    break\n",
    "\n",
    "# dataframe für die Anforderungen erstellen\n",
    "\n",
    "df_02 = pd.DataFrame(columns=['Klassifikation', 'Anforderung', 'Beschreibung', 'Zitat'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fortschritt: 1/15 API-Failures: 0 Save-Failures: 0 Requirement-Failures: 0 Interview-Failures: 0\n",
      "Fortschritt: 2/15 API-Failures: 0 Save-Failures: 0 Requirement-Failures: 0 Interview-Failures: 0\n",
      "Fortschritt: 3/15 API-Failures: 0 Save-Failures: 0 Requirement-Failures: 2 Interview-Failures: 0\n",
      "Fortschritt: 4/15 API-Failures: 0 Save-Failures: 0 Requirement-Failures: 2 Interview-Failures: 0\n",
      "Fortschritt: 5/15 API-Failures: 0 Save-Failures: 0 Requirement-Failures: 4 Interview-Failures: 0\n",
      "Fortschritt: 6/15 API-Failures: 0 Save-Failures: 0 Requirement-Failures: 4 Interview-Failures: 0\n",
      "Fortschritt: 7/15 API-Failures: 0 Save-Failures: 0 Requirement-Failures: 4 Interview-Failures: 0\n",
      "Fortschritt: 8/15 API-Failures: 0 Save-Failures: 0 Requirement-Failures: 4 Interview-Failures: 0\n",
      "Fortschritt: 9/15 API-Failures: 0 Save-Failures: 0 Requirement-Failures: 4 Interview-Failures: 0\n",
      "Fortschritt: 10/15 API-Failures: 0 Save-Failures: 0 Requirement-Failures: 4 Interview-Failures: 0\n",
      "Fortschritt: 11/15 API-Failures: 0 Save-Failures: 0 Requirement-Failures: 4 Interview-Failures: 0\n",
      "Fortschritt: 12/15 API-Failures: 0 Save-Failures: 0 Requirement-Failures: 4 Interview-Failures: 0\n",
      "Fortschritt: 13/15 API-Failures: 0 Save-Failures: 0 Requirement-Failures: 4 Interview-Failures: 0\n",
      "Fortschritt: 14/15 API-Failures: 0 Save-Failures: 0 Requirement-Failures: 7 Interview-Failures: 0\n",
      "Fortschritt: 15/15 API-Failures: 0 Save-Failures: 0 Requirement-Failures: 7 Interview-Failures: 0\n"
     ]
    }
   ],
   "source": [
    "# Iteratives Ausführen der Abfrage für alle Element im df_01[\"Interviewausschnitt\"]\n",
    "\n",
    "#model = \"gpt-4\"\n",
    "model = \"gpt-4-0314\"\n",
    "#model = \"gpt-3.5-turbo\"\n",
    "#model = \"gpt-3.5-turbo-0301\"\n",
    "\n",
    "api_failures = 0\n",
    "save_failures = 0\n",
    "req_failures = 0\n",
    "int_failures = 0\n",
    "n = 0\n",
    "\n",
    "for element in df_01[\"Interviewausschnitt\"]:\n",
    "    \n",
    "    n_elements = len(df_01[\"Interviewausschnitt\"])\n",
    "    n += 1\n",
    "\n",
    "    try:\n",
    "        text = element\n",
    "\n",
    "        messages =  [  \n",
    "        {'role':'system', 'content':'Du bist ein System, das Anforderungen in natürlich sprachlichen Interviews identifiziert und extrahiert.\\\n",
    "        Dir wird vom \"\"\"user\"\"\" ein Interviewausschnitt präsentiert. \\\n",
    "        In dem Interview geht es um die Entwicklung einer Anwendung zur Bereitstellung von medizinischem Fachwissen für Physiotherapeut_Innen. \\\n",
    "        Der Ausschnitt startet mit einer Frage durch einen Interviewer \"I\".\\\n",
    "        Der Interviewer stellt eine oder mehrere Fragen an den Interviewpartner \"B\".\\\n",
    "        Der Interviewpartner \"B\" antwortet auf die Frage.\\\n",
    "        Du analysierst den Interviewausschnitt und versuchst direkte Hinweise auf vom Interviewpartner \"B\" \\\n",
    "        gewünschte Funktionen der Anwendung zu identifizieren. \\\n",
    "        Ignoriere Anforderungen, die nur aus der Aussage des Interviewers \"I\" resultieren. \\\n",
    "        Du gibst anschließend eine Liste von Anforderungen aus, die du aus dem Interviewausschnitt extrahiert hast. \\\n",
    "        Die Anforderungen sollen in funktionale und nicht-funktionale Anforderungen unterteilt werden. \\\n",
    "        Du kannst auch eine Anforderung als unklar markieren, wenn du dir nicht sicher bist, ob sie eine Anforderung ist. \\\n",
    "        Es sollen keine impliziten Anforderungen ausgegeben werden. \\\n",
    "        Jede Anforderung soll mit einem Zitat aus dem Interviewausschnitt belegt werden. \\\n",
    "        Die Anforderungen soll nach folgendem Schema formuliert werden: Das System muss/kann/soll + Anforderung. \\\n",
    "        Gib das Ergenis deiner Analyse als CSV aus, nutze als Trennzeichen \";\" und folgende Struktur:\\\n",
    "        Funktional/nicht funktional/unklar; Anforderung; Beschreibung der Anforderung; Zitat aus Interviewausschnitt\\\n",
    "        '},\n",
    "        {'role':'user', 'content':text}]\n",
    "\n",
    "        try: \n",
    "            response = get_completion_from_messages(messages, model = model, temperature=0)\n",
    "            #print(response[0:100])\n",
    "        except:\n",
    "            #print(\"Fehler beim API Aufruf\")\n",
    "            api_failures += 1\n",
    "\n",
    "        try:\n",
    "            # Speichern der Antwort als Textdatei\n",
    "            now = datetime.datetime.now()\n",
    "            filename = \"/Users/dorianzwanzig/SIENA/responses/response-\" + str(model) + \"-\" + now.strftime(\"%Y-%m-%d_%H-%M-%S\") + \".txt\"\n",
    "            with open(filename, \"w\") as f:\n",
    "                f.write(response)\n",
    "        except:\n",
    "            #print(\"Fehler Speichern der Antwort\") \n",
    "            save_failures += 1  \n",
    "\n",
    "        try:\n",
    "            df_02 = df_02.append(text_to_dataframe(response), ignore_index=True)\n",
    "            df_02.dropna(inplace=True)\n",
    "            df_02.drop_duplicates(inplace=True)\n",
    "        except:\n",
    "            #print(\"Fehler beim Erweitern des Dataframes\")\n",
    "            req_failures += 1\n",
    "\n",
    "        print(\"Fortschritt: \" + str(n) + \"/\" + str(n_elements) + \" API-Failures: \" + str(api_failures) + \n",
    "              \" Save-Failures: \" + str(save_failures) + \" Requirement-Failures: \" + str(req_failures) + \n",
    "              \" Interview-Failures: \" + str(int_failures))\n",
    "\n",
    "    except:\n",
    "        #print(\"Fehler beim Verarbeiten des Interviewausschnitts\" + str(element[0:200]))\n",
    "        int_failures += 1\n",
    "\n",
    "filename_csv = \"requirements-\" + str(model) + now.strftime(\"%Y-%m-%d_%H-%M-%S\") + \".csv\"\n",
    "df_02.to_csv(filename_csv, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "requirements",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
